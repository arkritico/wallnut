/**
 * Pipeline File Upload via Supabase Storage (Presigned URLs)
 *
 * For files that exceed Vercel's 4.5 MB serverless body limit,
 * this module uploads them directly from the browser to Supabase Storage
 * using presigned upload URLs generated by the server.
 *
 * Flow:
 *   1. Client → POST /api/pipeline/upload-url { fileName, fileSize }  (tiny request)
 *   2. Server → generates signed upload URL via Supabase service key
 *   3. Client → PUT to signed URL (direct to Supabase, bypasses Vercel)
 *   4. Client → POST /api/pipeline { storagePaths, files[small], ... }  (tiny request)
 *   5. Server → downloads from Supabase Storage → runs pipeline
 *   6. Server → cleans up temp files after pipeline completes
 *
 * No Supabase auth needed on the client — the server generates presigned URLs.
 */

import { isSupabaseConfigured, getSupabase } from "./supabase";
import { createClient } from "@supabase/supabase-js";

// ── Constants ─────────────────────────────────────────────────

/** Files larger than this go to Supabase Storage instead of FormData */
export const LARGE_FILE_THRESHOLD = 4 * 1024 * 1024; // 4 MB

/** Storage bucket name (must exist in Supabase) */
const BUCKET_NAME = "pipeline-uploads";

// ── Types ─────────────────────────────────────────────────────

export interface StorageUploadResult {
  /** Files that were uploaded to Storage (path in bucket) */
  storagePaths: { fileName: string; storagePath: string; fileSize: number }[];
  /** Files small enough to include in FormData directly */
  smallFiles: File[];
  /** Files that failed to upload */
  errors: { fileName: string; error: string }[];
}

export interface UploadProgress {
  fileName: string;
  fileIndex: number;
  totalFiles: number;
  phase: "uploading" | "done" | "error";
  /** Upload progress 0-100 for current file (approximate) */
  percent?: number;
}

// ── Client-side: Upload large files via presigned URLs ────────

/**
 * Separate files into "small" (FormData-safe) and "large" (needs Storage upload).
 * Upload large files to Supabase Storage via presigned URLs (no client auth needed).
 */
export async function uploadLargeFilesToStorage(
  files: File[],
  onProgress?: (progress: UploadProgress) => void,
): Promise<StorageUploadResult> {
  const smallFiles: File[] = [];
  const largeFiles: File[] = [];

  for (const file of files) {
    if (file.size <= LARGE_FILE_THRESHOLD) {
      smallFiles.push(file);
    } else {
      largeFiles.push(file);
    }
  }

  // If no large files, no Storage needed
  if (largeFiles.length === 0) {
    return { storagePaths: [], smallFiles, errors: [] };
  }

  // Upload large files via presigned URLs
  const storagePaths: StorageUploadResult["storagePaths"] = [];
  const errors: StorageUploadResult["errors"] = [];

  for (let i = 0; i < largeFiles.length; i++) {
    const file = largeFiles[i];

    onProgress?.({
      fileName: file.name,
      fileIndex: i,
      totalFiles: largeFiles.length,
      phase: "uploading",
      percent: 0,
    });

    try {
      // Step 1: Get a presigned upload URL from the server
      const urlResponse = await fetch("/api/pipeline/upload-url", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          fileName: file.name,
          fileSize: file.size,
        }),
      });

      if (!urlResponse.ok) {
        const errBody = await urlResponse.json().catch(() => ({}));
        throw new Error(
          (errBody as Record<string, string>).error ||
          `Failed to get upload URL: HTTP ${urlResponse.status}`,
        );
      }

      const { signedUrl, token, storagePath } = await urlResponse.json() as {
        signedUrl: string;
        token: string;
        storagePath: string;
      };

      // Step 2: Upload file directly to Supabase Storage using the signed URL
      // Use uploadToSignedUrl via the Supabase client if available,
      // otherwise use a direct PUT request
      let uploadError: string | null = null;

      if (isSupabaseConfigured()) {
        const sb = getSupabase();
        if (sb) {
          const { error } = await sb.storage
            .from(BUCKET_NAME)
            .uploadToSignedUrl(storagePath, token, file);
          if (error) {
            uploadError = error.message;
          }
        }
      }

      // Fallback: direct PUT to the signed URL if Supabase client not available
      if (uploadError !== null || !isSupabaseConfigured()) {
        uploadError = null; // Reset for retry
        const putResponse = await fetch(signedUrl, {
          method: "PUT",
          body: file,
          headers: {
            "Content-Type": file.type || "application/octet-stream",
          },
        });

        if (!putResponse.ok) {
          uploadError = `Direct upload failed: HTTP ${putResponse.status}`;
        }
      }

      if (uploadError) {
        throw new Error(uploadError);
      }

      storagePaths.push({
        fileName: file.name,
        storagePath,
        fileSize: file.size,
      });

      onProgress?.({
        fileName: file.name,
        fileIndex: i,
        totalFiles: largeFiles.length,
        phase: "done",
        percent: 100,
      });
    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      errors.push({ fileName: file.name, error: message });

      onProgress?.({
        fileName: file.name,
        fileIndex: i,
        totalFiles: largeFiles.length,
        phase: "error",
      });
    }
  }

  return { storagePaths, smallFiles, errors };
}

// ── Server-side: download files from Storage ──────────────────

/**
 * Download a file from Supabase Storage and return it as a File object.
 * Used server-side in the pipeline API to retrieve large files.
 *
 * Uses a service-key client to bypass RLS (presigned uploads don't use user-scoped paths).
 */
export async function downloadFileFromStorage(
  storagePath: string,
  fileName: string,
): Promise<File> {
  const sb = getServerSupabase();

  const { data, error } = await sb.storage
    .from(BUCKET_NAME)
    .download(storagePath);

  if (error) {
    throw new Error(`Failed to download ${fileName} from Storage: ${error.message}`);
  }

  if (!data) {
    throw new Error(`No data returned for ${fileName}`);
  }

  // Supabase returns a Blob — convert to File
  const arrayBuffer = await data.arrayBuffer();
  const mimeType = guessMimeType(fileName);
  return new File([arrayBuffer], fileName, { type: mimeType });
}

/**
 * Clean up temporary pipeline upload files from Storage.
 * Call this after pipeline processing is complete.
 */
export async function cleanupStorageFiles(
  storagePaths: string[],
): Promise<void> {
  if (storagePaths.length === 0) return;

  try {
    const sb = getServerSupabase();
    await sb.storage.from(BUCKET_NAME).remove(storagePaths);
  } catch (err) {
    console.warn("Failed to cleanup pipeline upload files:", err);
  }
}

// ── Server-side Supabase client with service key ──────────────

/**
 * Create a Supabase client with the service role key for server-side operations.
 * Falls back to anon key if service key not available.
 */
function getServerSupabase() {
  const url = process.env.NEXT_PUBLIC_SUPABASE_URL;
  const key = process.env.SUPABASE_SERVICE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;

  if (!url || !key) {
    throw new Error("Supabase not configured (missing URL or key)");
  }

  return createClient(url, key);
}

// ── Helpers ───────────────────────────────────────────────────

function guessMimeType(fileName: string): string {
  const ext = fileName.split(".").pop()?.toLowerCase();
  switch (ext) {
    case "pdf": return "application/pdf";
    case "xls": return "application/vnd.ms-excel";
    case "xlsx": return "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet";
    case "csv": return "text/csv";
    case "ifc": return "application/x-step";
    default: return "application/octet-stream";
  }
}
