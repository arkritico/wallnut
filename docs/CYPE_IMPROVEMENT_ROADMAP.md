# üöÄ CYPE Scraping - Plano de Melhorias

**Data:** 2026-02-16
**Estado Atual:** 2 scrapers separados, sistemas desconectados, 33/~100 categorias
**Objetivo:** Sistema unificado, robusto, automatizado

---

## üìã Roadmap Priorizado

### ‚úÖ **FASE 1: Consolida√ß√£o** (2-3 dias)

**1.1. Unificar Scrapers**
- [ ] Criar `src/lib/cype-unified-scraper.ts`
- [ ] Base: V2 (mais simples, HTML-first)
- [ ] Adicionar features V1: breakdowns, variantes
- [ ] Deprecar V1 e V2 (manter como backup)

**1.2. Melhorar Parsing**
- [ ] Substituir regex por `cheerio`
- [ ] Extra√ß√£o de pre√ßos mais robusta
- [ ] Extra√ß√£o de breakdowns (materiais/m√£o-obra/equipamento)

**1.3. Robustez**
- [ ] Adaptive backoff (exponential retry)
- [ ] Circuit breaker (para quando falha X vezes seguidas)
- [ ] Logging estruturado (Winston/Pino)

**Resultado:** 1 scraper robusto, mais f√°cil de manter

---

### ‚úÖ **FASE 2: Integra√ß√£o** (2 dias)

**2.1. Conectar Matcher**
- [ ] Gerar `matcherDB` automaticamente do scraper
- [ ] Adicionar items do parametric como fallback
- [ ] Remover hardcoding dos 652 items

**2.2. Valida√ß√£o**
- [ ] Comparar pre√ßos scraper vs. parametric (detectar outliers)
- [ ] Validar soma de breakdown = total
- [ ] Validar unidades (m, m¬≤, m¬≥, Ud, etc.)

**2.3. Caching**
- [ ] Cache Redis (opcional) ou in-memory
- [ ] TTL 24h para pre√ßos
- [ ] Invalida√ß√£o inteligente

**Resultado:** Sistemas conectados, dados validados

---

### ‚úÖ **FASE 3: Automatiza√ß√£o** (3-4 dias)

**3.1. API Background Jobs**
```typescript
// POST /api/cype/scrape
{
  "categories": ["NAF", "EAB"],  // opcional, default: all
  "fullScrape": false,            // false = incremental
  "webhook": "https://..."        // opcional, notifica quando completo
}

// Resposta:
{
  "jobId": "job_abc123",
  "status": "queued",
  "estimatedTime": "2h"
}

// GET /api/cype/scrape/job_abc123
{
  "status": "running",
  "progress": 45,
  "itemsScraped": 567,
  "errors": 2
}
```

**3.2. Scheduled Jobs**
- [ ] GitHub Action: scrape di√°rio (2AM)
- [ ] Incremental: s√≥ categorias alteradas
- [ ] Diff report: o que mudou?

**3.3. Supabase Integration**
- [ ] Schema para CYPE prices
- [ ] Tabela: `cype_items`, `cype_components`, `cype_scrape_log`
- [ ] RLS policies
- [ ] Triggers para atualiza√ß√£o autom√°tica

**Resultado:** Sistema totalmente automatizado

---

### ‚úÖ **FASE 4: Descoberta Inteligente** (opcional, 2-3 dias)

**4.1. Manual Discovery UI**
```
Interface para utilizador:
- Input: categoria nova (ex: "Pinturas")
- Sistema sugere poss√≠veis URLs
- Utilizador valida/rejeita
- Auto-adiciona ao config
```

**4.2. Fallback para CSV/Excel**
```
Se categoria n√£o est√° no site:
- Aceitar upload CSV/Excel do CYPE
- Parser autom√°tico
- Importar para sistema
```

**4.3. ML-based Price Validation**
```
- Treinar modelo com pre√ßos hist√≥ricos
- Detectar anomalias (pre√ßo 10x normal = erro?)
- Sugerir corre√ß√µes
```

**Resultado:** Cobertura 100%, resiliente a mudan√ßas

---

## üéØ Quick Wins (Implementar J√Å)

### 1. Substituir Regex por Cheerio
```typescript
// ‚ùå ANTES (fr√°gil):
const priceMatch = html.match(/Custo total por m¬≤:\s*([\d,.]+)\s*‚Ç¨/);

// ‚úÖ DEPOIS (robusto):
import * as cheerio from 'cheerio';
const $ = cheerio.load(html);
const price = $('.total-cost').text().match(/[\d,.]+/)[0];
```

### 2. Adaptive Backoff
```typescript
async function fetchWithBackoff(url: string, retries = 5) {
  for (let i = 0; i < retries; i++) {
    try {
      return await fetch(url);
    } catch (err) {
      const delay = Math.min(1000 * (2 ** i), 30000); // max 30s
      console.log(`Retry ${i+1}/${retries} ap√≥s ${delay}ms`);
      await wait(delay);
    }
  }
  throw new Error(`Failed after ${retries} retries`);
}
```

### 3. Conectar Matcher ao Scraper
```typescript
// Em cype-matcher.ts:
export async function refreshMatcherDB() {
  const scrapedItems = JSON.parse(
    fs.readFileSync('data/cype-full.json', 'utf-8')
  ).items;

  MATCHER_DB = scrapedItems.map(item => ({
    code: item.code,
    description: item.description,
    keywords: extractKeywords(item.description),
    unitCost: item.totalCost,
    unit: item.unit
  }));

  console.log(`‚úÖ Matcher DB updated: ${MATCHER_DB.length} items`);
}
```

---

## üìä M√©tricas de Sucesso

| M√©trica | Antes | Meta | Como Medir |
|---------|-------|------|------------|
| **Tempo de scrape completo** | 2-4h | 1-2h | Timestamp start/end |
| **Taxa de erro** | ~15% | <5% | Errors / Total items |
| **Cobertura** | 33 categorias | 80+ categorias | Manual discovery |
| **Breakdowns v√°lidos** | 0% | 95% | Sum(breakdown) == total |
| **Uptime API** | N/A | 99% | Monitoriza√ß√£o |

---

## üõ†Ô∏è Stack Recomendado

| Componente | Tool | Porqu√™ |
|------------|------|--------|
| **HTML Parsing** | `cheerio` | Mais robusto que regex |
| **Job Queue** | `Inngest` ou `Bull` | Background jobs confi√°veis |
| **Logging** | `winston` | Structured logs, m√∫ltiplos transports |
| **Cache** | `node-cache` ou Redis | Fast lookups |
| **Scheduling** | GitHub Actions | Free, integrado |

---

## üö¶ Estado Atual vs. Estado Ideal

```
ANTES:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Scraper V1 ‚îÇ     ‚îÇ Matcher  ‚îÇ     ‚îÇ Parametric  ‚îÇ
‚îÇ  (complex)  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ (652 HW) ‚îÇ     ‚îÇ  (unused)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Scraper V2 ‚îÇ
‚îÇ  (simple)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Sistemas separados, dados est√°ticos

DEPOIS:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       Unified CYPE Scraper             ‚îÇ
‚îÇ  (robusto, adaptativo, monitorizado)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Matcher DB   ‚îÇ‚Üê‚îÄ‚îÄ Auto-generated
    ‚îÇ  (live data)  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Parametric   ‚îÇ‚Üê‚îÄ‚îÄ Fallback + Validation
    ‚îÇ  Engine       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Supabase    ‚îÇ‚Üê‚îÄ‚îÄ Persistent storage
    ‚îÇ   (+ cache)   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Sistema unificado, auto-atualizado
```

---

## üìå Pr√≥ximos Passos

1. **Decidir**: Qual fase come√ßar? (Recomendo Fase 1)
2. **Branch**: `feature/cype-unified-scraper`
3. **Implementar**: Seguir checklist acima
4. **Testar**: Scrape 5-10 categorias primeiro
5. **Deploy**: Gradual, monitorizar

---

**Quest√µes?**
- Precisa de ajuda com alguma fase espec√≠fica?
- Quer ver c√≥digo exemplo para algum componente?
- D√∫vidas sobre a arquitetura?
